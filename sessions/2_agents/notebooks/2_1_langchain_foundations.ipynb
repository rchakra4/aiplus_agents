{"cells":[{"cell_type":"markdown","metadata":{"id":"3rhCXe3TVZUu"},"source":["# Langchain Foundations"]},{"cell_type":"markdown","metadata":{"id":"vpIGXn1WMPYX"},"source":["This notebook introduces the foundations of **LangChain**, a framework that simplifies working with Large Language Models (LLMs). LangChain provides:\n","- Abstraction layers to streamline interactions with various LLMs.\n","- Standardized interfaces for working with different types of AI models.\n","- Tools and utilities for developing complex AI applications.\n"]},{"cell_type":"markdown","metadata":{},"source":["\n","This notebook is divided into two sections:\n","1. Step by Step: configuration, templates, and basic chaining\n","2. Combined Output: highlighting step-wise vs. chain execution\n"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Step by Step"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":23248,"status":"ok","timestamp":1730640528207,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"ctgU6B2gVZUy","outputId":"b689d762-4587-47ec-8ec5-fa439dec9f83"},"outputs":[],"source":["# install notebook package dependencies\n","!pip install langchain==0.3.2\n","!pip install langchain-openai==0.2.0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10404,"status":"ok","timestamp":1730640538601,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"mfh1oPfKMPYY","outputId":"454c5218-0f84-42ae-9cf1-f1fbb61d79e8"},"outputs":[],"source":["import getpass\n","import os\n","\n","# set openai api key\n","os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter your OpenAi Key:\")"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7270,"status":"ok","timestamp":1730640545864,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"OUirlDnxVZU0"},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","\n","# initialize the model\n","model = ChatOpenAI(model=\"gpt-4o-mini\")"]},{"cell_type":"markdown","metadata":{"id":"suWCPVemMPYZ"},"source":["LangChain provides message templates to structure interactions:\n","\n","SystemMessage defines instructions or context.\n","HumanMessage represents user input."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1063,"status":"ok","timestamp":1730640546925,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"aHrRGCUaVZU0","outputId":"c6d57b27-a64e-49d2-e835-4d50ecdf07d6"},"outputs":[],"source":["from langchain_core.messages import HumanMessage, SystemMessage\n","\n","# system and human message templates\n","messages = [\n","    SystemMessage(content=\"You are an expert financial analyst.\"),\n","    HumanMessage(content=\"How much has NVIDIA's revenue grown over time?\"),\n","]\n","\n","# print message\n","print(\"message template\")\n","print(messages)\n","\n","# e.g., system message\n","print(\"\\nparse message template\")\n","print(messages[0].type)\n","print(messages[0].content)\n","\n","# invoke the model with messages\n","print(\"\\ninvoke model\")\n","print(model.invoke(messages))"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":5,"status":"ok","timestamp":1730640546926,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"-DMVfBQKVZU1"},"outputs":[],"source":["from langchain_core.output_parsers import StrOutputParser\n","\n","# initialize prebuilt output parser\n","parser = StrOutputParser()"]},{"cell_type":"markdown","metadata":{"id":"s-XG7-4wMPYa"},"source":["Using model.invoke(messages), we pass in our defined messages and receive the model's response - simplifying model interaction"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":492,"status":"ok","timestamp":1730640547413,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"GefIhsXEVZU1"},"outputs":[],"source":["# invoke model\n","result = model.invoke(messages)"]},{"cell_type":"markdown","metadata":{"id":"f7H9WKtGMPYa"},"source":["Output parsers help structure and format responses. Here, the StrOutputParser converts model outputs into standardized string formats."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":13,"status":"ok","timestamp":1730640547414,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"juWEwQhrVZU1","outputId":"7c7fa3fb-885f-4a34-c9f8-3f5151591725"},"outputs":[],"source":["# pass through string output parser\n","parser.invoke(result)"]},{"cell_type":"markdown","metadata":{"id":"jqJt0VyyMPYa"},"source":["Invoke a predefined chain, which processes messages and outputs a structured response."]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1730640547414,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"O8w6dkfNVZU1"},"outputs":[],"source":["# chain together model and parser\n","chain = model | parser"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":775,"status":"ok","timestamp":1730640548179,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"WvHtFip3VZU2","outputId":"6384ff67-2625-44c4-cde4-46b9cbb76017"},"outputs":[],"source":["# output is now a string\n","chain.invoke(messages)"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1730640548179,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"nDNMNYpKVZU2"},"outputs":[],"source":["from langchain_core.prompts import ChatPromptTemplate"]},{"cell_type":"markdown","metadata":{"id":"UEbwgsK3MPYa"},"source":["We set up a system message template that includes a {company} variable as a placeholder. This enables dynamic updates to the template based on specific user input."]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1730640548179,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"ATXRru5pVZU2"},"outputs":[],"source":["# system template with placeholder language variable\n","system_template = \"You are an expert financial analyst that specializes in analyzing {company}.\""]},{"cell_type":"markdown","metadata":{"id":"MIZPP8ewMPYa"},"source":["We construct a Chat Prompt Template by combining the system message with a user message placeholder {text}."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1730640548179,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"3RxAa82aVZU2","outputId":"ad772ef3-1af4-441d-d8c0-6deb86c67bdf"},"outputs":[],"source":["# construct chat prompt template with system template and user message placeholder\n","prompt_template = ChatPromptTemplate.from_messages(\n","    [(\"system\", system_template), (\"user\", \"{text}\")]\n",")\n","\n","# print the prompt template\n","print(prompt_template.messages)"]},{"cell_type":"markdown","metadata":{"id":"qTccr6GBMPYa"},"source":["Using .invoke(), we pass specific values for company and text."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1730640548179,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"sxjDwWB2VZU2","outputId":"7eb12637-7b62-42a6-c4f6-d1667994c036"},"outputs":[],"source":["# pass in variables\n","result = prompt_template.invoke({\"company\": \"NVIDIA\", \"text\": \"How much has NVIDIA's revenue grown over time?\"})\n","\n","result"]},{"cell_type":"markdown","metadata":{"id":"Z1qVlxMqMPYa"},"source":["The to_messages() method converts the result back into a list of SystemMessage and HumanMessage objects."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1730640548179,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"s8frfnBdVZU2","outputId":"a3a4cbc1-0d0f-484a-b105-637f812138cc"},"outputs":[],"source":["# same messages structure as directly using system and human message templates\n","result.to_messages()"]},{"cell_type":"markdown","metadata":{"id":"kLSgg-ZXMPYa"},"source":["LangChain enables us to combine templates, models, and parsers into a single chain object."]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":159,"status":"ok","timestamp":1730640548336,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"pwb449C-VZU2"},"outputs":[],"source":["# chain all together\n","chain = prompt_template | model | parser"]},{"cell_type":"markdown","metadata":{"id":"N8SG1bmZMPYb"},"source":["We invoke the full chain with company and text input, executing each component (prompt, model, and parser) in sequence. The output is a complete, processed response ready for display or further processing."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":463,"status":"ok","timestamp":1730640548797,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"56sFvbhDVZU2","outputId":"fa02debf-0ad9-4816-b1ed-ed01a0dfe9fd"},"outputs":[],"source":["# invoke the chain with input variables\n","chain.invoke({\"company\": \"NVIDIA\", \"text\": \"How much has NVIDIA's revenue grown over time?\"})"]},{"cell_type":"markdown","metadata":{"id":"m1lwOzNAVZU2"},"source":["## 2. Combined Output"]},{"cell_type":"markdown","metadata":{"id":"TOvFWiw6MPYb"},"source":["Here, we compare step-wise execution (invoking each element individually) with chain execution (invoking the chain as a single unit)."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":774,"status":"ok","timestamp":1730640549569,"user":{"displayName":"Nihar Reddy Kondam","userId":"16040040032885228293"},"user_tz":300},"id":"Ci6qe4obVZU3","outputId":"213b67b4-1913-416c-8672-9f2b8016357c"},"outputs":[],"source":["from langchain_openai import ChatOpenAI\n","from langchain_core.output_parsers import StrOutputParser\n","from langchain_core.prompts import ChatPromptTemplate\n","# define the model\n","model = ChatOpenAI(model=\"gpt-4o-mini\")\n","# define the prompt template\n","system_template = \"You are an expert financial analyst that specializes in analyzing {company}.\"\n","prompt_template = ChatPromptTemplate.from_messages(\n","    [(\"system\", system_template), (\"user\", \"{text}\")]\n",")\n","# define the output parser\n","parser = StrOutputParser()\n","# step wise result\n","result = prompt_template.invoke({\"company\": \"NVIDIA\", \"text\": \"How much has NVIDIA's revenue grown over time?\"})\n","result = model.invoke(result)\n","result = parser.invoke(result)\n","print(\"Step-wise:\")\n","print(result)\n","# chain result\n","print(\"\\nChain:\")\n","chain = prompt_template | model | parser\n","result = chain.invoke({\"company\": \"NVIDIA\", \"text\": \"How much has NVIDIA's revenue grown over time?\"})\n","print(result)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.18"}},"nbformat":4,"nbformat_minor":0}
